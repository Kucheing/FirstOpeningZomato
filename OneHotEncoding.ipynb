{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "565b9f88",
   "metadata": {},
   "source": [
    "# One Hot Encoding in Machine Learning\n",
    "\n",
    "One Hot Encoding is a method for converting categorical variables into a binary format. It creates new columns for each category where 1 means the category is present and 0 means it is not. The primary purpose of One Hot Encoding is to ensure that categorical data can be effectively used in machine learning models.\n",
    "\n",
    "**Importance of One Hot Encoding**\n",
    "We use one hot Encoding because:\n",
    "\n",
    "1. **Eliminating Ordinality**: Many categorical variables have no inherent order (e.g., \"Male\" and \"Female\"). If we were to assign numerical values (e.g., Male = 0, Female = 1) the model might mistakenly interpret this as a ranking and lead to biased predictions. One Hot Encoding eliminates this risk by treating each category independently.\n",
    "\n",
    "2. **Improving Model Performance**: By providing a more detailed representation of categorical variables. One Hot Encoding can help to improve the performance of machine learning models. It allows models to capture complex relationships within the data that might be missed if categorical variables were treated as single entities.\n",
    "\n",
    "3. **Compatibility with Algorithms**: Many machine learning algorithms particularly based on linear regression and gradient descent which require numerical input. It ensures that categorical variables are converted into a suitable format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79378331",
   "metadata": {},
   "source": [
    "# Implementing One-Hot Encoding Using Python\n",
    "\n",
    "To implement one-hot encoding in Python we can use either the Pandas library or the Scikit-learn library both of which provide efficient and convenient methods for this task.\n",
    "\n",
    "1. Using Pandas\n",
    "\n",
    "Pandas offers the get_dummies function which is a simple and effective way to perform one-hot encoding. This method converts categorical variables into multiple binary columns.\n",
    "\n",
    "- For example the Gender column with values 'M' and 'F' becomes two binary columns: Gender_F and Gender_M.\n",
    "- drop_first=True in pandas drops one redundant column e.g., keeps only Gender_F to avoid multicollinearity.\n",
    "\n",
    "**OBSERVATION**\n",
    "- get_dummies() converts Gender (M, F) into binary columns: Gender_M\n",
    "- Remarks (Good, Nice, Great) becomes Remarks_Good, Remarks_Great, Remarks_Nice\n",
    "- drop_first=True removes one column to avoid multicollinearity\n",
    "- OneHotEncoder creates the same binary representation for all categories\n",
    "- Employee id remains unchanged since it's already numeric\n",
    "\n",
    "**FINDINGS**\n",
    "- One-Hot Encoding transforms text categories into 1s and 0s so models can understand them\n",
    "- Each category gets its own column (1 = present, 0 = absent)\n",
    "- This prevents models from treating categories as ranked or ordered\n",
    "- Both Pandas and Scikit-Learn produce equivalent results; Pandas is simpler, Scikit-Learn is better for pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdc81fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Employee Data:\n",
      "   Employee id Gender Remarks\n",
      "0           10      M    Good\n",
      "1           20      F    Nice\n",
      "2           15      F    Good\n",
      "3           25      M   Great\n",
      "4           30      F    Nice\n",
      "\n",
      "One-Hot Encoded Data using Pandas:\n",
      "   Employee id  Gender_M  Remarks_Great  Remarks_Nice\n",
      "0           10      True          False         False\n",
      "1           20     False          False          True\n",
      "2           15     False          False         False\n",
      "3           25      True           True         False\n",
      "4           30     False          False          True\n",
      "\n",
      "One-Hot Encoded Data using Scikit-Learn:\n",
      "   Employee id  Gender_F  Gender_M  Remarks_Good  Remarks_Great  Remarks_Nice\n",
      "0           10       0.0       1.0           1.0            0.0           0.0\n",
      "1           20       1.0       0.0           0.0            0.0           1.0\n",
      "2           15       1.0       0.0           1.0            0.0           0.0\n",
      "3           25       0.0       1.0           0.0            1.0           0.0\n",
      "4           30       1.0       0.0           0.0            0.0           1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "data = {\n",
    "    'Employee id': [10, 20, 15, 25, 30],\n",
    "    'Gender': ['M', 'F', 'F', 'M', 'F'],\n",
    "    'Remarks': ['Good', 'Nice', 'Good', 'Great', 'Nice']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(f\"Original Employee Data:\\n{df}\\n\")\n",
    "# Use pd.get_dummies() to one-hot encode the categorical columns\n",
    "df_pandas_encoded = pd.get_dummies(df, columns=['Gender', 'Remarks'], drop_first=True)\n",
    "print(f\"One-Hot Encoded Data using Pandas:\\n{df_pandas_encoded}\\n\")\n",
    "\n",
    "categorical_columns = ['Gender', 'Remarks']\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "one_hot_encoded = encoder.fit_transform(df[categorical_columns])\n",
    "\n",
    "one_hot_df = pd.DataFrame(one_hot_encoded, \n",
    "                          columns=encoder.get_feature_names_out(categorical_columns))\n",
    "\n",
    "df_sklearn_encoded = pd.concat([df.drop(categorical_columns, axis=1), one_hot_df], axis=1)\n",
    "\n",
    "print(f\"One-Hot Encoded Data using Scikit-Learn:\\n{df_sklearn_encoded}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3abdfc6",
   "metadata": {},
   "source": [
    "2. One Hot Encoding using Scikit Learn Library\n",
    "Scikit-learn(sklearn) is a popular machine-learning library in Python that provide numerous tools for data preprocessing. It provides a OneHotEncoder function that we use for encoding categorical and numerical variables into binary vectors. Using df.select_dtypes(include=['object']) in Scikit Learn Library:\n",
    "\n",
    "This selects only the columns with categorical data (data type object).\n",
    "In this case, ['Gender', 'Remarks'] are identified as categorical columns.\n",
    "\n",
    "**Both Pandas and Scikit-Learn offer robust solutions for one-hot encoding.**\n",
    "\n",
    "- Use Pandas get_dummies() when you need quick and simple encoding.\n",
    "- Use Scikit-Learn OneHotEncoder when working within a machine learning pipeline or when you need finer control over encoding behavior.\n",
    "\n",
    "**OBSERVATION**\n",
    "- select_dtypes(include=['object']) automatically detects all text columns (Gender, Remarks)\n",
    "- OneHotEncoder converts each category into binary columns\n",
    "- All binary columns are added back to the original DataFrame\n",
    "- Original categorical columns are dropped after encoding\n",
    "- Employee id remains untouched since it's numeric\n",
    "\n",
    "**FINDINGS**\n",
    "- This approach is automatic and scalable - it finds categorical columns without manually specifying them\n",
    "- The encoded data is now entirely numeric and ready for machine learning models\n",
    "- Removes the original text columns to avoid redundancy\n",
    "- Better than manual column selection when working with large datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ac04058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Employee data : \n",
      "   Employee id Gender Remarks\n",
      "0           10      M    Good\n",
      "1           20      F    Nice\n",
      "2           15      F    Good\n",
      "3           25      M   Great\n",
      "4           30      F    Nice\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "data = {'Employee id': [10, 20, 15, 25, 30],\n",
    "        'Gender': ['M', 'F', 'F', 'M', 'F'],\n",
    "        'Remarks': ['Good', 'Nice', 'Good', 'Great', 'Nice'],\n",
    "        }\n",
    "df = pd.DataFrame(data)\n",
    "print(f\"Employee data : \\n{df}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72fe56e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = df.select_dtypes(include=['object']).columns.tolist()\n",
    "encoder = OneHotEncoder(sparse_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "367a071f",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoded = encoder.fit_transform(df[categorical_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0858ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_df = pd.DataFrame(one_hot_encoded, columns=encoder.get_feature_names_out(categorical_columns))\n",
    "print(f\"{one_hot_df}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "942ee63c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Employee id Gender Remarks  Gender_F  Gender_M  Remarks_Good  \\\n",
      "0           10      M    Good       0.0       1.0           1.0   \n",
      "1           20      F    Nice       1.0       0.0           0.0   \n",
      "2           15      F    Good       1.0       0.0           1.0   \n",
      "3           25      M   Great       0.0       1.0           0.0   \n",
      "4           30      F    Nice       1.0       0.0           0.0   \n",
      "\n",
      "   Remarks_Great  Remarks_Nice  \n",
      "0            0.0           0.0  \n",
      "1            0.0           1.0  \n",
      "2            0.0           0.0  \n",
      "3            1.0           0.0  \n",
      "4            0.0           1.0  \n"
     ]
    }
   ],
   "source": [
    "df_encoded = pd.concat([df, one_hot_df], axis=1)\n",
    "print(f\"{df_encoded}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0775bc32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded Employee data : \n",
      "   Employee id  Gender_F  Gender_M  Remarks_Good  Remarks_Great  Remarks_Nice\n",
      "0           10       0.0       1.0           1.0            0.0           0.0\n",
      "1           20       1.0       0.0           0.0            0.0           1.0\n",
      "2           15       1.0       0.0           1.0            0.0           0.0\n",
      "3           25       0.0       1.0           0.0            1.0           0.0\n",
      "4           30       1.0       0.0           0.0            0.0           1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_encoded = df_encoded.drop(categorical_columns, axis=1)\n",
    "print(f\"Encoded Employee data : \\n{df_encoded}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca23424",
   "metadata": {},
   "source": [
    "# Advantages and Disadvantages of One Hot Encoding\n",
    "\n",
    "**Advantages of Using One Hot Encoding**\n",
    "1. It allows the use of categorical variables in models that require numerical input.\n",
    "2. It can improve model performance by providing more information to the model about the categorical variable.\n",
    "3. It can help to avoid the problem of ordinality which can occur when a categorical variable has a natural ordering (e.g. \"small\", \"medium\", \"large\").\n",
    "\n",
    "**Disadvantages of Using One Hot Encoding**\n",
    "1. It can lead to increased dimensionality as a separate column is created for each category in the variable. This can make the model more complex and slow to train.\n",
    "2. It can lead to sparse data as most observations will have a value of 0 in most of the one-hot encoded columns.\n",
    "3. It can lead to overfitting especially if there are many categories in the variable and the sample size is relatively small.\n",
    "\n",
    "# Best Practices for One Hot Encoding\n",
    "\n",
    "To make the most of One Hot Encoding and we must consider the following best practices:\n",
    "\n",
    "1. Limit the Number of Categories: If you have high cardinality categorical variables consider limiting the number of categories through grouping or feature engineering.\n",
    "2. Use Feature Selection: Implement feature selection techniques to identify and retain only the most relevant features after One Hot Encoding. This can help reduce dimensionality and improve model performance.\n",
    "3. Monitor Model Performance: Regularly evaluate your model's performance after applying One Hot Encoding. If you notice signs of overfitting or other issues consider alternative encoding methods.\n",
    "4. Understand Your Data: Before applying One Hot Encoding take the time to understand the nature of your categorical variables. Determine whether they have a natural order and whether One Hot Encoding is appropriate.\n",
    "\n",
    "# Alternatives to One Hot Encoding\n",
    "\n",
    "While One Hot Encoding is a popular choice for handling categorical data there are several alternatives that may be more suitable depending on the context:\n",
    "\n",
    "1. Label Encoding: In cases where categorical variables have a natural order (e.g., \"Low,\" \"Medium,\" \"High\") label encoding can be a better option. This method assigns a unique integer to each category without introducing the same risks of hierarchy misinterpretation as with nominal data.\n",
    "2. Binary Encoding: This technique combines the benefits of One Hot Encoding and label encoding. It converts categories into binary numbers and then creates binary columns. This method can reduce dimensionality while preserving information.\n",
    "3. Target Encoding: In target encoding, we replace each category with the mean of the target variable for that category. This method can be particularly useful for categorical variables with a high number of unique values but it also carries a risk of leakage if not handled properly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
